//! KDL Index-Based Parser (Stage 2 of Two-Stage Parsing)
//!
//! This parser consumes a StructuralIndex generated by Stage 1.
//! It uses structural offsets to jump across tokens while keeping
//! parsing semantics aligned with the streaming parser.

const std = @import("std");
const constants = @import("../constants.zig");
const simd = @import("../simd.zig");
const structural = @import("structural.zig");
const unicode = @import("../unicode.zig");
const numbers = @import("../numbers.zig");
const value_builder = @import("../value_builder.zig");
const StreamDocument = @import("../stream_types.zig").StreamDocument;
const StringRef = @import("../stream_types.zig").StringRef;
const NodeHandle = @import("../stream_types.zig").NodeHandle;
const StreamValue = @import("../stream_types.zig").StreamValue;
const DecodeUtf8Result = @TypeOf(unicode.decodeUtf8(""));

pub const ParseError = error{
    UnexpectedToken,
    UnexpectedEof,
    InvalidNumber,
    InvalidString,
    InvalidEscape,
    InvalidSyntax,
    MaxDepthExceeded,
    UnsupportedFeature,
    OutOfMemory,
};

pub const Options = struct {
    max_depth: u16 = constants.DEFAULT_MAX_DEPTH,
};

const TokenKind = enum {
    identifier,
    quoted_string,
    raw_string,
    multiline_string,
    number,
    keyword,
};

const TokenInfo = struct {
    kind: TokenKind,
    start: usize,
    end: usize,
    text: []const u8,
    str_ref: ?StringRef = null,
};

const ContiguousOps = struct {
    inline fn len(source: *const []const u8) usize {
        return source.*.len;
    }

    inline fn byteAt(source: *const []const u8, pos: usize) ?u8 {
        if (pos >= source.*.len) return null;
        return source.*[pos];
    }

    inline fn spanFrom(source: *const []const u8, pos: usize) []const u8 {
        if (pos >= source.*.len) return "";
        return source.*[pos..];
    }

    inline fn slice(
        source: *const []const u8,
        allocator: std.mem.Allocator,
        scratch: *std.ArrayList(u8),
        start: usize,
        end: usize,
    ) std.mem.Allocator.Error![]const u8 {
        _ = allocator;
        _ = scratch;
        return source.*[start..end];
    }
};

const ChunkedSourceCursor = struct {
    source: structural.ChunkedSource,
    chunk_index: usize = 0,
    chunk_start: usize = 0,
    chunk_end: usize = 0,

    fn init(source: structural.ChunkedSource) ChunkedSourceCursor {
        var cursor = ChunkedSourceCursor{ .source = source };
        if (source.chunks.len > 0) {
            cursor.chunk_start = source.offsets[0];
            cursor.chunk_end = cursor.chunk_start + source.chunks[0].len;
        }
        return cursor;
    }
};

const ChunkedOps = struct {
    inline fn len(source: *const ChunkedSourceCursor) usize {
        return source.source.total_len;
    }

    inline fn spanFrom(source: *ChunkedSourceCursor, pos: usize) []const u8 {
        if (pos >= source.source.total_len) return "";
        ensureChunkFor(source, pos);
        const chunk = currentChunk(source);
        return chunk[(pos - source.chunk_start)..];
    }

    inline fn byteAt(source: *ChunkedSourceCursor, pos: usize) ?u8 {
        if (pos >= source.source.total_len) return null;
        ensureChunkFor(source, pos);
        const chunk = currentChunk(source);
        return chunk[pos - source.chunk_start];
    }

    inline fn slice(
        source: *ChunkedSourceCursor,
        allocator: std.mem.Allocator,
        scratch: *std.ArrayList(u8),
        start: usize,
        end: usize,
    ) std.mem.Allocator.Error![]const u8 {
        if (end <= start) return "";
        if (start >= source.source.total_len) return "";
        ensureChunkFor(source, start);
        const chunk = currentChunk(source);
        if (end <= source.chunk_end) {
            return chunk[(start - source.chunk_start)..(end - source.chunk_start)];
        }

        scratch.clearRetainingCapacity();
        var pos = start;
        while (pos < end) {
            ensureChunkFor(source, pos);
            const cur = currentChunk(source);
            const local_start = pos - source.chunk_start;
            const take = @min(end, source.chunk_end) - pos;
            try scratch.appendSlice(allocator, cur[local_start..][0..take]);
            pos += take;
        }
        return scratch.items;
    }

    inline fn currentChunk(source: *const ChunkedSourceCursor) []const u8 {
        const chunk = source.source.chunks[source.chunk_index];
        return chunk.data[0..chunk.len];
    }

    inline fn ensureChunkFor(source: *ChunkedSourceCursor, pos: usize) void {
        if (pos >= source.chunk_start and pos < source.chunk_end) return;
        if (source.source.chunks.len == 0) {
            source.chunk_start = 0;
            source.chunk_end = 0;
            return;
        }
        if (pos >= source.chunk_end) {
            while (source.chunk_index + 1 < source.source.chunks.len and pos >= source.source.offsets[source.chunk_index + 1]) {
                source.chunk_index += 1;
            }
        } else if (pos < source.chunk_start) {
            var lo: usize = 0;
            var hi: usize = source.source.offsets.len;
            while (lo + 1 < hi) {
                const mid = (lo + hi) / 2;
                if (source.source.offsets[mid] <= pos) {
                    lo = mid;
                } else {
                    hi = mid;
                }
            }
            source.chunk_index = lo;
        }
        source.chunk_start = source.source.offsets[source.chunk_index];
        source.chunk_end = source.chunk_start + source.source.chunks[source.chunk_index].len;
    }
};

fn IndexParserImpl(comptime SourceType: type, comptime Ops: type) type {
    return struct {
        const Self = @This();

        allocator: std.mem.Allocator,
        source: SourceType,
        index: structural.StructuralIndex,
        idx_pos: usize = 0,
        cursor: usize = 0,
        doc: *StreamDocument,
        depth: u16 = 0,
        options: Options,
        scratch: std.ArrayList(u8) = .empty,

        pub fn init(
            allocator: std.mem.Allocator,
            source: SourceType,
            index: structural.StructuralIndex,
            doc: *StreamDocument,
            options: Options,
        ) Self {
            return Self{
                .allocator = allocator,
                .source = source,
                .index = index,
                .doc = doc,
                .options = options,
            };
        }

        pub fn deinit(self: *Self) void {
            self.scratch.deinit(self.allocator);
        }

        pub fn parse(self: *Self) ParseError!void {
            self.skipBOM();

            while (self.cursor < self.sourceLen()) {
                self.skipIgnored();
                if (self.cursor >= self.sourceLen()) break;

                const c = self.peek().?;
                if (isNewline(c)) {
                    self.consumeNewline();
                    continue;
                }
                if (self.isSlashdash()) {
                    return ParseError.UnsupportedFeature;
                }

                _ = try self.parseNode(null);
                self.skipIgnored();
            }
        }

        inline fn sourceLen(self: *Self) usize {
            return Ops.len(&self.source);
        }

        inline fn byteAt(self: *Self, pos: usize) ?u8 {
            return Ops.byteAt(&self.source, pos);
        }

        inline fn spanFrom(self: *Self, pos: usize) []const u8 {
            return Ops.spanFrom(&self.source, pos);
        }

        fn sliceRange(self: *Self, start: usize, end: usize) ParseError![]const u8 {
            return Ops.slice(&self.source, self.allocator, &self.scratch, start, end) catch return ParseError.OutOfMemory;
        }

        fn parseNode(self: *Self, parent: ?NodeHandle) ParseError!NodeHandle {
        if (self.depth >= self.options.max_depth) {
            return ParseError.MaxDepthExceeded;
        }
        self.depth += 1;
        defer self.depth -= 1;

        self.skipIgnored();

        var type_annot = StringRef.empty;
        if (self.peek() == @as(?u8, '(')) {
            self.advanceCursor(1);
            self.skipIgnored();
            type_annot = try self.parseIdentifierOrString();
            self.skipIgnored();
            if (self.peek() != @as(?u8, ')')) return ParseError.InvalidSyntax;
            self.advanceCursor(1);
        }

        self.skipIgnored();
        const name = try self.parseIdentifierOrString();

        const arg_start: u64 = @intCast(self.doc.values.arguments.items.len);
        const prop_start: u64 = @intCast(self.doc.values.properties.items.len);

        while (true) {
            self.skipIgnored();
            if (self.cursor >= self.sourceLen()) break;
            const c = self.peek().?;
            if (c == ';' or isNewline(c) or c == '{' or c == '}') break;
            if (self.isSlashdash()) {
                return ParseError.UnsupportedFeature;
            }
            try self.parseArgumentOrProperty();
        }

        const arg_end: u64 = @intCast(self.doc.values.arguments.items.len);
        const prop_end: u64 = @intCast(self.doc.values.properties.items.len);

        const node = self.doc.nodes.addNode(
            name,
            type_annot,
            parent,
            .{ .start = arg_start, .count = arg_end - arg_start },
            .{ .start = prop_start, .count = prop_end - prop_start },
        ) catch return ParseError.OutOfMemory;

        if (parent == null) {
            self.doc.addRoot(node) catch return ParseError.OutOfMemory;
        } else {
            self.doc.nodes.linkChild(parent.?, node);
        }

        self.skipIgnored();
        var had_children = false;
        if (self.peek() == @as(?u8, '{')) {
            had_children = true;
            self.advanceCursor(1);
            while (true) {
                self.skipIgnored();
                while (self.peek()) |nc| {
                    if (!isNewline(nc)) break;
                    self.consumeNewline();
                    self.skipIgnored();
                }
                if (self.peek() == @as(?u8, '}')) {
                    self.advanceCursor(1);
                    break;
                }
                if (self.cursor >= self.sourceLen()) return ParseError.UnexpectedEof;
                if (self.isSlashdash()) {
                    return ParseError.UnsupportedFeature;
                }
                _ = try self.parseNode(node);
            }
        }

        self.skipIgnored();
        if (self.peek()) |term| {
            if (term == ';') {
                self.advanceCursor(1);
            } else if (isNewline(term)) {
                self.consumeNewline();
            } else if (had_children and term != '}') {
                return ParseError.UnexpectedToken;
            }
        }

        return node;
    }

    fn parseArgumentOrProperty(self: *Self) ParseError!void {
        var type_annot = StringRef.empty;
        if (self.peek() == @as(?u8, '(')) {
            self.advanceCursor(1);
            self.skipIgnored();
            type_annot = try self.parseIdentifierOrString();
            self.skipIgnored();
            if (self.peek() != @as(?u8, ')')) return ParseError.InvalidSyntax;
            self.advanceCursor(1);
        }

        self.skipIgnored();
        const token = try self.parseToken();

        self.skipIgnored();
        if (self.peek() == @as(?u8, '=')) {
            if (type_annot.len != 0) return ParseError.InvalidSyntax;
            if (token.str_ref == null or token.kind == .number or token.kind == .keyword) {
                return ParseError.InvalidSyntax;
            }
            self.advanceCursor(1);
            self.skipIgnored();

            var val_type = StringRef.empty;
            if (self.peek() == @as(?u8, '(')) {
                self.advanceCursor(1);
                self.skipIgnored();
                val_type = try self.parseIdentifierOrString();
                self.skipIgnored();
                if (self.peek() != @as(?u8, ')')) return ParseError.InvalidSyntax;
                self.advanceCursor(1);
            }

            const value = try self.parseValue();
            _ = self.doc.values.addProperty(.{
                .name = token.str_ref.?,
                .value = value,
                .type_annotation = val_type,
            }) catch return ParseError.OutOfMemory;
        } else {
            const value = try self.parseValueFromToken(token);
            _ = self.doc.values.addArgument(.{
                .value = value,
                .type_annotation = type_annot,
            }) catch return ParseError.OutOfMemory;
        }
    }

    fn parseValue(self: *Self) ParseError!StreamValue {
        const token = try self.parseToken();
        return self.parseValueFromToken(token);
    }

    fn parseValueFromToken(self: *Self, token: TokenInfo) ParseError!StreamValue {
        switch (token.kind) {
            .identifier, .quoted_string, .raw_string, .multiline_string => {
                return StreamValue{ .string = token.str_ref.? };
            },
            .keyword => {
                if (std.mem.eql(u8, token.text, "#true")) return StreamValue{ .boolean = true };
                if (std.mem.eql(u8, token.text, "#false")) return StreamValue{ .boolean = false };
                if (std.mem.eql(u8, token.text, "#null")) return StreamValue{ .null_value = {} };
                if (std.mem.eql(u8, token.text, "#inf")) return StreamValue{ .positive_inf = {} };
                if (std.mem.eql(u8, token.text, "#-inf")) return StreamValue{ .negative_inf = {} };
                if (std.mem.eql(u8, token.text, "#nan")) return StreamValue{ .nan_value = {} };
                return ParseError.UnexpectedToken;
            },
            .number => return self.parseNumber(token.text),
        }
    }

    fn parseNumber(self: *Self, text: []const u8) ParseError!StreamValue {
        if (text.len == 0) return ParseError.InvalidNumber;

        var start: usize = 0;
        if (text[0] == '-' or text[0] == '+') start = 1;

        if (start + 1 < text.len and text[start] == '0') {
            const prefix = text[start + 1];
            if (prefix == 'x' or prefix == 'X') {
                const val = numbers.parseRadixInteger(self.allocator, text, 2, 16) catch return ParseError.InvalidNumber;
                return StreamValue{ .integer = val };
            }
            if (prefix == 'o' or prefix == 'O') {
                const val = numbers.parseRadixInteger(self.allocator, text, 2, 8) catch return ParseError.InvalidNumber;
                return StreamValue{ .integer = val };
            }
            if (prefix == 'b' or prefix == 'B') {
                const val = numbers.parseRadixInteger(self.allocator, text, 2, 2) catch return ParseError.InvalidNumber;
                return StreamValue{ .integer = val };
            }
        }

        if (std.mem.indexOfAny(u8, text, ".eE") != null) {
            const result = numbers.parseFloat(self.allocator, text) catch return ParseError.InvalidNumber;
            defer if (result.original) |orig| self.allocator.free(orig);
            const orig_text = result.original orelse text;
            const ref = self.doc.strings.add(orig_text) catch return ParseError.OutOfMemory;
            return StreamValue{ .float = .{ .value = result.value, .original = ref } };
        }

        const val = numbers.parseDecimalInteger(self.allocator, text) catch return ParseError.InvalidNumber;
        return StreamValue{ .integer = val };
    }

    fn parseIdentifierOrString(self: *Self) ParseError!StringRef {
        const token = try self.parseToken();
        switch (token.kind) {
            .identifier, .quoted_string, .raw_string, .multiline_string => return token.str_ref.?,
            else => return ParseError.UnexpectedToken,
        }
    }

    fn parseToken(self: *Self) ParseError!TokenInfo {
        if (self.cursor >= self.sourceLen()) return ParseError.UnexpectedEof;

        const start = self.cursor;
        const c = self.peek().?;

        if (c == '"') {
            return self.parseQuotedStringToken();
        }

        if (c == '#') {
            if (self.isRawStringStart()) {
                return self.parseRawStringToken();
            }
            const slice = try self.readHashToken();
            return TokenInfo{
                .kind = .keyword,
                .start = start,
                .end = self.cursor,
                .text = slice,
            };
        }

        if (c == '.') {
            if (self.peekAhead(1)) |next| {
                if (std.ascii.isDigit(next)) return ParseError.InvalidNumber;
            }
            return self.parseIdentifierToken();
        }

        if (c == '+' or c == '-') {
            if (self.peekAhead(1)) |next| {
                if (std.ascii.isDigit(next)) return self.parseNumberToken();
            }
            return self.parseIdentifierToken();
        }

        if (std.ascii.isDigit(c)) {
            return self.parseNumberToken();
        }

        return self.parseIdentifierToken();
    }

    fn parseIdentifierToken(self: *Self) ParseError!TokenInfo {
        const start = self.cursor;
        const slice = try self.readBareSlice();
        if (slice.len == 0) return ParseError.UnexpectedToken;
        if (isBareKeyword(slice)) return ParseError.InvalidSyntax;

        const ref = value_builder.buildIdentifier(&self.doc.strings, slice) catch return ParseError.OutOfMemory;
        return TokenInfo{
            .kind = .identifier,
            .start = start,
            .end = self.cursor,
            .text = slice,
            .str_ref = ref,
        };
    }

    fn parseNumberToken(self: *Self) ParseError!TokenInfo {
        const start = self.cursor;
        const slice = try self.readBareSlice();
        if (slice.len == 0) return ParseError.InvalidNumber;
        return TokenInfo{
            .kind = .number,
            .start = start,
            .end = self.cursor,
            .text = slice,
        };
    }

    fn parseQuotedStringToken(self: *Self) ParseError!TokenInfo {
        const start = self.cursor;
        const len = self.sourceLen();
        const is_multiline = self.cursor + 2 < len and
            self.byteAt(self.cursor + 1).? == '"' and
            self.byteAt(self.cursor + 2).? == '"';

        if (is_multiline) {
            const close_pos = self.findNextQuotePos(self.cursor + 3) orelse return ParseError.UnexpectedEof;
            if (close_pos + 2 >= len or
                self.byteAt(close_pos + 1).? != '"' or
                self.byteAt(close_pos + 2).? != '"')
            {
                return ParseError.InvalidString;
            }
            const end_pos = close_pos + 2;
            const text = try self.sliceRange(start, end_pos + 1);
            const ref = value_builder.buildMultilineString(&self.doc.strings, text) catch |err| return mapStringError(err);
            self.advanceCursorTo(end_pos + 1);
            return TokenInfo{
                .kind = .multiline_string,
                .start = start,
                .end = self.cursor,
                .text = text,
                .str_ref = ref,
            };
        }

        const close_pos = self.findNextQuotePos(self.cursor + 1) orelse return ParseError.UnexpectedEof;
        const text = try self.sliceRange(start, close_pos + 1);
        const ref = value_builder.buildQuotedString(&self.doc.strings, text) catch |err| return mapStringError(err);
        self.advanceCursorTo(close_pos + 1);
        return TokenInfo{
            .kind = .quoted_string,
            .start = start,
            .end = self.cursor,
            .text = text,
            .str_ref = ref,
        };
    }

    fn parseRawStringToken(self: *Self) ParseError!TokenInfo {
        const start = self.cursor;
        const len = self.sourceLen();

        var hash_count: usize = 0;
        while (self.peekAhead(hash_count)) |ch| : (hash_count += 1) {
            if (ch != '#') break;
        }
        if (hash_count == 0) return ParseError.InvalidString;

        const quote_pos = start + hash_count;
        if (quote_pos >= len or self.byteAt(quote_pos).? != '"') {
            return ParseError.InvalidString;
        }

        const is_multiline = quote_pos + 2 < len and
            self.byteAt(quote_pos + 1).? == '"' and
            self.byteAt(quote_pos + 2).? == '"';

        const search_start: usize = quote_pos + (if (is_multiline) @as(usize, 3) else 1);
        const close_pos = self.findNextQuotePos(search_start) orelse return ParseError.UnexpectedEof;

        var end_pos: usize = 0;
        if (is_multiline) {
            if (close_pos + 2 >= len or
                self.byteAt(close_pos + 1).? != '"' or
                self.byteAt(close_pos + 2).? != '"')
            {
                return ParseError.InvalidString;
            }
            if (!self.matchesHashesAt(close_pos + 3, hash_count)) {
                return ParseError.InvalidString;
            }
            end_pos = close_pos + 2 + hash_count;
        } else {
            if (!self.matchesHashesAt(close_pos + 1, hash_count)) {
                return ParseError.InvalidString;
            }
            end_pos = close_pos + hash_count;
        }

        if (end_pos >= len) return ParseError.UnexpectedEof;
        const text = try self.sliceRange(start, end_pos + 1);
        const ref = value_builder.buildRawString(&self.doc.strings, text) catch |err| return mapStringError(err);
        self.advanceCursorTo(end_pos + 1);
        return TokenInfo{
            .kind = .raw_string,
            .start = start,
            .end = self.cursor,
            .text = text,
            .str_ref = ref,
        };
    }

    fn findNextQuotePos(self: *Self, start_pos: usize) ?usize {
        var i = self.idx_pos;
        while (i < self.index.count and @as(usize, @intCast(self.index.indices[i])) < start_pos) {
            i += 1;
        }
        while (i < self.index.count) : (i += 1) {
            const pos = @as(usize, @intCast(self.index.indices[i]));
            if (pos < start_pos) continue;
            if (pos >= self.sourceLen()) break;
            if (self.byteAt(pos).? == '"') {
                self.idx_pos = i;
                return pos;
            }
        }
        return null;
    }

    fn readBareSlice(self: *Self) ParseError![]const u8 {
        const start = self.cursor;
        if (start >= self.sourceLen()) return "";
        const end = self.findTokenEnd(start);
        self.advanceCursorTo(end);
        return self.sliceRange(start, end);
    }

    fn readHashToken(self: *Self) ParseError![]const u8 {
        const start = self.cursor;
        if (start >= self.sourceLen()) return "";

        var pos = start + 1;
        while (pos < self.sourceLen()) : (pos += 1) {
            const c = self.byteAt(pos).?;
            if (c < 0x80 and isTokenTerminator(c)) break;
        }

        self.advanceCursorTo(pos);
        return self.sliceRange(start, pos);
    }

    fn findTokenEnd(self: *Self, start: usize) usize {
        var pos = start;
        const len = self.sourceLen();
        while (pos < len) : (pos += 1) {
            const c = self.byteAt(pos).?;
            if (c < 0x80 and isTokenTerminator(c)) break;
        }
        return pos;
    }

    fn nextStructuralPos(self: *Self) usize {
        self.syncIndex();
        if (self.idx_pos >= self.index.count) return self.sourceLen();
        return @intCast(self.index.indices[self.idx_pos]);
    }

    fn nextStructuralPosFrom(self: *Self, pos: usize) usize {
        var i = self.idx_pos;
        while (i < self.index.count and @as(usize, @intCast(self.index.indices[i])) < pos) {
            i += 1;
        }
        if (i >= self.index.count) {
            self.idx_pos = self.index.count;
            return self.sourceLen();
        }
        self.idx_pos = i;
        return @intCast(self.index.indices[i]);
    }

    fn syncIndex(self: *Self) void {
        while (self.idx_pos < self.index.count and @as(usize, @intCast(self.index.indices[self.idx_pos])) < self.cursor) {
            self.idx_pos += 1;
        }
    }

    fn advanceCursor(self: *Self, count: usize) void {
        if (count == 0) return;
        self.cursor += count;
        self.syncIndex();
    }

    fn advanceCursorTo(self: *Self, pos: usize) void {
        self.cursor = pos;
        self.syncIndex();
    }

    fn skipIgnored(self: *Self) void {
        while (self.cursor < self.sourceLen()) {
            const available = self.spanFrom(self.cursor);
            const ws_len = simd.findWhitespaceLength(available);
            if (ws_len > 0) {
                self.advanceCursor(ws_len);
                continue;
            }

            const c = self.peek().?;

            if (c == '\\' and self.trySkipLineContinuation()) {
                continue;
            }

            if (c == '/') {
                if (self.peekAhead(1)) |next| {
                    if (next == '/') {
                        self.cursor += 2;
                        while (self.cursor < self.sourceLen()) {
                            const nc = self.peek().?;
                            if (isNewline(nc)) break;
                            self.cursor += 1;
                        }
                        self.syncIndex();
                        continue;
                    }
                    if (next == '*') {
                        self.cursor += 2;
                        var depth: usize = 1;
                        while (self.cursor + 1 < self.sourceLen() and depth > 0) {
                            const a = self.byteAt(self.cursor).?;
                            const b = self.byteAt(self.cursor + 1).?;
                            if (a == '/' and b == '*') {
                                depth += 1;
                                self.cursor += 2;
                                continue;
                            }
                            if (a == '*' and b == '/') {
                                depth -= 1;
                                self.cursor += 2;
                                continue;
                            }
                            self.cursor += 1;
                        }
                        self.syncIndex();
                        continue;
                    }
                }
            }

            if (c >= 0x80) {
                if (self.decodeUtf8At()) |decoded| {
                    if (unicode.isWhitespace(decoded.codepoint)) {
                        self.advanceCursor(decoded.len);
                        continue;
                    }
                }
            }

            break;
        }
    }

    fn decodeUtf8At(self: *Self) DecodeUtf8Result {
        const span = self.spanFrom(self.cursor);
        if (span.len >= 4) {
            return unicode.decodeUtf8(span);
        }

        var buf: [4]u8 = undefined;
        var i: usize = 0;
        while (i < buf.len and self.cursor + i < self.sourceLen()) : (i += 1) {
            buf[i] = self.byteAt(self.cursor + i).?;
        }
        return unicode.decodeUtf8(buf[0..i]);
    }

    fn trySkipLineContinuation(self: *Self) bool {
        if (self.peek() != @as(?u8, '\\')) return false;

        var pos = self.cursor + 1;
        while (pos < self.sourceLen()) {
            const c = self.byteAt(pos).?;
            if (c == ' ' or c == '\t') {
                pos += 1;
                continue;
            }
            break;
        }

        if (pos < self.sourceLen() and isNewline(self.byteAt(pos).?)) {
            if (self.byteAt(pos).? == '\r' and pos + 1 < self.sourceLen() and self.byteAt(pos + 1).? == '\n') {
                pos += 2;
            } else {
                pos += 1;
            }
            self.advanceCursorTo(pos);
            return true;
        }

        return false;
    }

    fn consumeNewline(self: *Self) void {
        if (self.cursor >= self.sourceLen()) return;
        if (self.byteAt(self.cursor).? == '\r' and self.cursor + 1 < self.sourceLen() and self.byteAt(self.cursor + 1).? == '\n') {
            self.advanceCursor(2);
        } else {
            self.advanceCursor(1);
        }
    }

    fn peek(self: *Self) ?u8 {
        return self.byteAt(self.cursor);
    }

    fn peekAhead(self: *Self, offset: usize) ?u8 {
        const pos = self.cursor + offset;
        return self.byteAt(pos);
    }

    fn skipBOM(self: *Self) void {
        if (self.sourceLen() >= 3 and
            self.byteAt(0).? == 0xEF and
            self.byteAt(1).? == 0xBB and
            self.byteAt(2).? == 0xBF)
        {
            self.advanceCursorTo(3);
        }
    }

    fn isSlashdash(self: *Self) bool {
        return self.peek() == @as(?u8, '/') and self.peekAhead(1) == @as(?u8, '-');
    }

    fn isRawStringStart(self: *Self) bool {
        if (self.peek() != @as(?u8, '#')) return false;
        var pos = self.cursor;
        while (pos < self.sourceLen() and self.byteAt(pos).? == '#') {
            pos += 1;
        }
        return pos < self.sourceLen() and self.byteAt(pos).? == '"';
    }

    fn matchesHashesAt(self: *Self, start: usize, count: usize) bool {
        if (start + count > self.sourceLen()) return false;
        var i: usize = 0;
        while (i < count) : (i += 1) {
            if (self.byteAt(start + i).? != '#') return false;
        }
        return true;
    }
};

}

pub const IndexParser = IndexParserImpl([]const u8, ContiguousOps);
pub const ChunkedIndexParser = IndexParserImpl(ChunkedSourceCursor, ChunkedOps);

fn isNewline(c: u8) bool {
    return c == '\n' or c == '\r';
}

fn isTokenTerminator(c: u8) bool {
    return switch (c) {
        ' ', '\t', '\n', '\r' => true,
        '(', ')', '{', '}', '[', ']', '/', '\\', '"', '#', ';', '=' => true,
        0x00...0x08, 0x0B, 0x0C, 0x0E...0x1F, 0x7F => true,
        else => false,
    };
}

fn isBareKeyword(text: []const u8) bool {
    return std.mem.eql(u8, text, "true") or
        std.mem.eql(u8, text, "false") or
        std.mem.eql(u8, text, "null") or
        std.mem.eql(u8, text, "inf") or
        std.mem.eql(u8, text, "nan");
}

fn mapStringError(err: value_builder.Error) ParseError {
    return switch (err) {
        error.InvalidString => ParseError.InvalidString,
        error.InvalidEscape => ParseError.InvalidEscape,
        error.OutOfMemory => ParseError.OutOfMemory,
    };
}

pub fn initChunkedParser(
    allocator: std.mem.Allocator,
    source: structural.ChunkedSource,
    index: structural.StructuralIndex,
    doc: *StreamDocument,
    options: Options,
) ChunkedIndexParser {
    return ChunkedIndexParser.init(allocator, ChunkedSourceCursor.init(source), index, doc, options);
}

pub fn parseWithOptions(allocator: std.mem.Allocator, source: []const u8, options: Options) ParseError!StreamDocument {
    const index = structural.scan(allocator, source, .{}) catch return ParseError.OutOfMemory;
    defer index.deinit(allocator);

    var doc = StreamDocument.init(allocator) catch return ParseError.OutOfMemory;
    errdefer doc.deinit();

    var parser = IndexParser.init(allocator, source, index, &doc, options);
    defer parser.deinit();
    try parser.parse();
    return doc;
}

pub fn parse(allocator: std.mem.Allocator, source: []const u8) ParseError!StreamDocument {
    return parseWithOptions(allocator, source, .{});
}

test "IndexParser basic" {
    const allocator = std.testing.allocator;
    const source = "node key=\"value\" { child 123; }";
    var doc = try parse(allocator, source);
    defer doc.deinit();

    try std.testing.expectEqual(@as(usize, 2), doc.nodes.count());
}
